{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 123   Leica AT403 394315\n",
      "1 183   Leica AT403 394315\n",
      "3 1815   Leica AT403 394315\n",
      "4 1936   Leica AT403 394315\n",
      "5 1949   Leica AT403 394315\n",
      "10 2319   Leica AT403 394315\n",
      "|      | Collection               | Group   | Point   |      R |   Theta |      Phi |   Planar offset |   Radial offset | 8   | 9   | 10   | 11   | 12   | 13   | 14   | 15   |      [U-r] |   [U-theta] |     [U-phi] |   [U-mag] | Timestamp         | 21   | Last Face          | Tracker               | Reflector               | Target                  | RMS Error       | Temperature       | Pressure   | Humidity                                       | Mode                                                  | Status          | Type measurement   | 33                           | Level compensation 1   | Level compensation 2                  |   Level compensation 3 |         varx |     CoVar_xy |     CoVar_xz |    CoVar_xy |        Var_y |     CoVar_yz |     CoVar_xz |    CoVar_yz |   value |\n",
      "|-----:|:-------------------------|:--------|:--------|-------:|--------:|---------:|----------------:|----------------:|:----|:----|:-----|:-----|:-----|:-----|:-----|:-----|-----------:|------------:|------------:|----------:|:------------------|:-----|:-------------------|:----------------------|:------------------------|:------------------------|:----------------|:------------------|:-----------|:-----------------------------------------------|:------------------------------------------------------|:----------------|:-------------------|:-----------------------------|:-----------------------|:--------------------------------------|-----------------------:|-------------:|-------------:|-------------:|------------:|-------------:|-------------:|-------------:|------------:|--------:|\n",
      "| 1748 | 1.5 Gev Ring survey      | ST86    | L0404   | 174310 | 2.15691 |  82.5607 |           19.05 |           19.05 |     |     |      |      |      |      |      |      | 0.00496348 | 1.6595e-06  | 2.53496e-06 | 0.0104486 | 06/30/23 13:43:37 |      | Leica AT401 390741 | Reflector 'RRR 1.5in' | Target 'SMR: RRR 1.5in' | RMS Error 0.002833 mm   | Weather:T=21.6C | P=1000.4hPA(mbar) | H=57.0%    | Measure Time Discrete Point Standard Pt. To SA | emScon FAST Measurement Mode Used Laser Status: Ready | Front/Back=True | Separate Obs       | std components: 1 = 0.001905 | 2 = 0.000019           | 3 = 0.001050 mm Level Compensation ON |            4.83985e-05 | -2.28971e-06 | -1.10012e-05 | -2.28971e-06 | 4.98809e-05 |  1.51246e-05 | -1.10012e-05 |  1.51246e-05 | 0.000119401 |     nan |\n",
      "| 2175 | 1.5 Gev Beamlines survey | ST058   | L0826   | 129679 | 1.91477 |  84.5057 |           19.05 |           19.05 |     |     |      |      |      |      |      |      | 0.0125374  | 5.52138e-06 | 5.52002e-06 | 0.0216336 | 07/17/23 11:53:15 |      | Face 2:            | Leica AT403 394315    | Reflector 'RRR 1.5in'   | Target 'SMR: RRR 1.5in' | Weather:T=21.7C | P=1004.4hPA(mbar) | H=61.7%    | Measure Time Discrete Point Standard Pt. To SA | emScon FAST Measurement Mode Used Laser Status: Ready | Front/Back=True | Separate Obs       | std components: 1 = 0.000000 | 2 = 0.000000           | 3 = 0.000000 mm Level Compensation ON |            0.000309636 |  8.83552e-06 | -1.51299e-05 |  8.83552e-06 | 0.000315586 |  1.08705e-05 | -1.51299e-05 |  1.08705e-05 | 0.000303319 |     nan |\n",
      "| 2178 | 1.5 Gev Beamlines survey | ST058   | L0902   | 137205 | 2.80366 |  83.9046 |           19.05 |           19.05 |     |     |      |      |      |      |      |      | 0.0263734  | 1.53649e-05 | 1.44743e-05 | 0.0568815 | 07/17/23 11:54:50 |      | Face 2:            | Leica AT403 394315    | Reflector 'RRR 1.5in'   | Target 'SMR: RRR 1.5in' | Weather:T=21.7C | P=1004.5hPA(mbar) | H=61.6%    | Measure Time Discrete Point Standard Pt. To SA | emScon FAST Measurement Mode Used Laser Status: Ready | Front/Back=True | Separate Obs       | std components: 1 = 0.000000 | 2 = 0.000000           | 3 = 0.000000 mm Level Compensation ON |            0.00146423  | -0.000102519 | -0.000587071 | -0.000102519 | 0.00261008  | -5.21112e-05 | -0.000587071 | -5.21112e-05 | 0.00232077  |     nan |\n",
      "| 2192 | 1.5 Gev Beamlines survey | ST060   | L1039   | 143516 | 1.7628  | 103.225  |           19.05 |           19.05 |     |     |      |      |      |      |      |      | 0.0143731  | 6.42034e-06 | 6.23885e-06 | 0.0263797 | 07/17/23 14:40:07 |      | Face 2:            | Leica AT403 394315    | Reflector 'RRR 1.5in'   | Target 'SMR: RRR 1.5in' | Weather:T=21.9C | P=1004.7hPA(mbar) | H=60.2%    | Measure Time Discrete Point Standard Pt. To SA | emScon FAST Measurement Mode Used Laser Status: Ready | Front/Back=True | Separate Obs       | std components: 1 = 0.000000 | 2 = 0.000000           | 3 = 0.000000 mm Level Compensation ON |            0.000425429 |  3.54642e-05 |  5.59134e-05 |  3.54642e-05 | 0.000483507 | -2.64831e-05 |  5.59134e-05 | -2.64831e-05 | 0.000458551 |     nan |\n",
      "| 2211 | 1.5 Gev Beamlines survey | ST061   | L1035   | 137179 | 1.83565 | 101.872  |           19.05 |           19.05 |     |     |      |      |      |      |      |      | 0.0209139  | 1.24722e-05 | 1.25757e-05 | 0.0468818 | 07/17/23 15:10:56 |      | Face 2:            | Leica AT403 394315    | Reflector 'RRR 1.5in'   | Target 'SMR: RRR 1.5in' | Weather:T=21.8C | P=1004.6hPA(mbar) | H=59.8%    | Measure Time Discrete Point Standard Pt. To SA | emScon FAST Measurement Mode Used Laser Status: Ready | Front/Back=True | Separate Obs       | std components: 1 = 0.000000 | 2 = 0.000000           | 3 = 0.000000 mm Level Compensation ON |            0.000994806 | -0.000162957 |  0.000268479 | -0.000162957 | 0.00177798  |  5.36339e-05 |  0.000268479 |  5.36339e-05 | 0.00172217  |     nan |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "ver = 13\n",
    "file1 = f\"C:/Users/alelen/Documents/Export Data/All_points_{ver}.txt\"\n",
    "path = \"C:/Users/alelen/Documents/Export Data/\"\n",
    "fields = [\"Collection\"]\n",
    "# df = pd.read_csv(file1, skiprows=5, delimiter=\",\", on_bad_lines=\"skip\", usecols=fields, skip_blank_lines=True)\n",
    "# df = pd.read_csv(file1, skiprows=5, sep=\", \", on_bad_lines=\"skip\", skip_blank_lines=True)\n",
    "df = pd.read_csv(file1, skiprows=6, sep=\",\", header=None, on_bad_lines=\"skip\", skip_blank_lines=True, engine=\"python\")\n",
    "df.rename(columns={0:\"Collection\", 1:\"Group\", 2:\"Point\", 3:\"R\", 4:\"Theta\", 5:\"Phi\", 6:\"Planar offset\", 7:\"Radial offset\",\n",
    "                   16:\"[U-r]\", 17:\"[U-theta]\", 18:\"[U-phi]\", 19:\"[U-mag]\",\n",
    "                   20:\"Timestamp\", 22:\"Last Face\", 23:\"Tracker\", 24:\"Reflector\", 25:\"Target\",\n",
    "                   26:\"RMS Error\", 27:\"Temperature\", 28:\"Pressure\", 29:\"Humidity\",\n",
    "                   30:\"Mode\", 31:\"Status\", 32:\"Type measurement\", \n",
    "                   34:\"Level compensation 1\", 35:\"Level compensation 2\", 36:\"Level compensation 3\",\n",
    "                   37:\"varx\", 38:\"CoVar_xy\", 39:\"CoVar_xz\", 40:\"CoVar_xy\", 41:\"Var_y\", 42:\"CoVar_yz\", \n",
    "                   43:\"CoVar_xz\", 44:\"CoVar_yz\", 45:\"value\"},inplace=True)\n",
    "\n",
    "# df['Group'] = df['Group'].str.replace(\"  \", \"\")\n",
    "# df['Point'] = df['Point'].str.replace(\"  \", \"\")\n",
    "# df['Point'] = df['Point'].str.replace(\"  \", \"\")\n",
    "\n",
    "# nani = pd.NA\n",
    "# type(df['[Var(z)]'].iloc[2820])\n",
    "value = \"Var-z\"\n",
    "# p = df.query(\"( value != value and not varx.isnull() ) or ( value.isnull() and not varx.isnull()  ) \").to_markdown(); print(p)\n",
    "i_change = df.query(\"( value != value and not varx.isnull() ) or ( value.isnull() and not varx.isnull()  ) \").index\n",
    "\n",
    "colnames= df.columns.values; #print(colnames[22:-1]) #print(colnames[23:])\n",
    "\n",
    "coln_track_from = colnames[22:-1]\n",
    "coln_track_to = colnames[23:]\n",
    "# for i,val in enumerate(df['Last Face'].iloc[i_change]):\n",
    "\n",
    "#     if(val == \"  Leica AT403 394315\"):\n",
    "#         for j,edit in enumerate(coln_track_to):\n",
    "#             print(j, edit, df.loc[(i_change[i]), (coln_track_from[j])])\n",
    "            # df.loc[i_change[i], (coln_track_to[j])] = df.loc[i_change[i], (coln_track_from[j])]\n",
    "\n",
    "            # df.loc[i_change[i], (colnames[22])] = \"Face 2 - Works!\"\n",
    "        \n",
    "y = list(df.loc[(i_change[0]), (colnames[22:-1])])\n",
    "z = colnames[23:]\n",
    "zz = colnames[22:-1]\n",
    "\n",
    "\n",
    "len(y), len(z), len(zz)\n",
    "save_index = 123\n",
    "copy_list = list(df.loc[(i_change[0]), (coln_track_from)].values)\n",
    "\n",
    "# df.loc[i_change[0], (colnames[22])] = \"Face 2\"\n",
    "df.loc[i_change[0], coln_track_to]\n",
    "len(copy_list), len(coln_track_from)\n",
    "# print(len(colnames))\n",
    "# x  =df.to_markdown(); print(x)\n",
    "# df\n",
    "# i_change = [123]\n",
    "df1 = df.copy()\n",
    "for i,val in enumerate(i_change):\n",
    "    # print(i,val)\n",
    "    if(df.loc[val, df.columns[22]] == \"  Leica AT403 394315\"):\n",
    "        print(i,val, df.loc[val, df.columns[22]])\n",
    "        for j,edit_col in enumerate(coln_track_from):\n",
    "            # print(j,edit_col, \">\", coln_track_to[j])\n",
    "            # print(\"######### new -----------\")\n",
    "            # print(j,coln_track_from[j], \">\",coln_track_to[j])\n",
    "            # print(j,df1.loc[val, df1.columns[22+j]], \">\", df.loc[val, df.columns[23+j]])\n",
    "\n",
    "            p = df1.loc[i_change, df.columns[22+j]]\n",
    "            # print(p.to_markdown())\n",
    "            # print('into')\n",
    "            p = df.loc[i_change, df.columns[23+j]]\n",
    "            # print(p.to_markdown())\n",
    "            x = (\"\").join(list(str(df1.loc[val, df1.columns[22+j]])))\n",
    "            \n",
    "            # print('insert x=', x)\n",
    "            df.loc[val, df.columns[23+j]] = np.nan\n",
    "            df.loc[val, df.columns[23+j]] = x\n",
    "            df.loc[val, df.columns[22]] = \"Face 2\"\n",
    "\n",
    "            p = df.loc[i_change, df.columns[23+j]]\n",
    "            # print(p.to_markdown())\n",
    "\n",
    "x = list(df1.loc[i_change, (coln_track_from)[0]])\n",
    "# print(df.loc[i_change, (coln_track_to[0])])\n",
    "# df.loc[i_change, (coln_track_to[0])] = x\n",
    "# print(df.loc[i_change, (coln_track_to[0])])\n",
    "p = df.query(\"( value != value and not varx.isnull() ) or ( value.isnull() and not varx.isnull()  ) \").to_markdown(); print(p)\n",
    "# p=df.loc[i_change, df.columns[22:]].to_markdown();print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Collection   | Group   | Point   | R   | Theta   | Phi   | Planar offset   | Radial offset   | 8   | 9   | 10   | 11   | 12   | 13   | 14   | 15   | [U-r]   | [U-theta]   | [U-phi]   | [U-mag]   | Timestamp   | 21   | Last Face   | Tracker   | Reflector   | Target   | RMS Error   | Temperature   | Pressure   | Humidity   | Mode   | Status   | Type measurement   | 33   | Level compensation 1   | Level compensation 2   | Level compensation 3   | varx   | CoVar_xy   | CoVar_xz   | CoVar_xy   | Var_y   | CoVar_yz   | CoVar_xz   | CoVar_yz   | value   |\n",
      "|--------------|---------|---------|-----|---------|-------|-----------------|-----------------|-----|-----|------|------|------|------|------|------|---------|-------------|-----------|-----------|-------------|------|-------------|-----------|-------------|----------|-------------|---------------|------------|------------|--------|----------|--------------------|------|------------------------|------------------------|------------------------|--------|------------|------------|------------|---------|------------|------------|------------|---------|\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "ver = 13\n",
    "file1 = f\"C:/Users/alelen/Documents/Export Data/All_points_{ver}.txt\"\n",
    "path = \"C:/Users/alelen/Documents/Export Data/\"\n",
    "fields = [\"Collection\"]\n",
    "# df = pd.read_csv(file1, skiprows=5, delimiter=\",\", on_bad_lines=\"skip\", usecols=fields, skip_blank_lines=True)\n",
    "# df = pd.read_csv(file1, skiprows=5, sep=\", \", on_bad_lines=\"skip\", skip_blank_lines=True)\n",
    "df = pd.read_csv(file1, skiprows=6, sep=\",\", header=None, on_bad_lines=\"skip\", skip_blank_lines=True, engine=\"python\")\n",
    "df.rename(columns={0:\"Collection\", 1:\"Group\", 2:\"Point\", 3:\"R\", 4:\"Theta\", 5:\"Phi\", 6:\"Planar offset\", 7:\"Radial offset\",\n",
    "                   16:\"[U-r]\", 17:\"[U-theta]\", 18:\"[U-phi]\", 19:\"[U-mag]\",\n",
    "                   20:\"Timestamp\", 22:\"Last Face\", 23:\"Tracker\", 24:\"Reflector\", 25:\"Target\",\n",
    "                   26:\"RMS Error\", 27:\"Temperature\", 28:\"Pressure\", 29:\"Humidity\",\n",
    "                   30:\"Mode\", 31:\"Status\", 32:\"Type measurement\", \n",
    "                   34:\"Level compensation 1\", 35:\"Level compensation 2\", 36:\"Level compensation 3\",\n",
    "                   37:\"varx\", 38:\"CoVar_xy\", 39:\"CoVar_xz\", 40:\"CoVar_xy\", 41:\"Var_y\", 42:\"CoVar_yz\", \n",
    "                   43:\"CoVar_xz\", 44:\"CoVar_yz\", 45:\"value\"},inplace=True)\n",
    "\n",
    "# df['Group'] = df['Group'].str.replace(\"  \", \"\")\n",
    "# df['Point'] = df['Point'].str.replace(\"  \", \"\")\n",
    "# df['Point'] = df['Point'].str.replace(\"  \", \"\")\n",
    "\n",
    "value = \"Var-z\"\n",
    "# p = df.query(\"( value != value and not varx.isnull() ) or ( value.isnull() and not varx.isnull()  ) \").to_markdown(); print(p)\n",
    "i_change = df.query(\"( value != value and not varx.isnull() ) or ( value.isnull() and not varx.isnull()  ) \").index\n",
    "\n",
    "colnames= df.columns.values; #print(colnames[22:-1]) #print(colnames[23:])\n",
    "\n",
    "coln_track_from = colnames[22:-1]\n",
    "coln_track_to = colnames[23:]\n",
    "\n",
    "coln_track_from_rms = colnames[26:-1]\n",
    "coln_track_to_rms = colnames[26:]\n",
    "\n",
    "        \n",
    "y = list(df.loc[(i_change[0]), (colnames[22:-1])])\n",
    "z = colnames[23:]\n",
    "zz = colnames[22:-1]\n",
    "\n",
    "\n",
    "len(y), len(z), len(zz)\n",
    "save_index = 123\n",
    "copy_list = list(df.loc[(i_change[0]), (coln_track_from)].values)\n",
    "\n",
    "df.loc[i_change[0], coln_track_to]\n",
    "len(copy_list), len(coln_track_from)\n",
    "\n",
    "def df_switch(i,val, df, coln_track_from, col_number, REPLACE_WITH):\n",
    "\n",
    "    for j,edit_col in enumerate(coln_track_from):\n",
    "        x = (\"\").join(list(str(df1.loc[val, df1.columns[col_number+j]])))\n",
    "\n",
    "        df.loc[val, df.columns[col_number+j+1]] = np.nan\n",
    "        df.loc[val, df.columns[col_number+j+1]] = x\n",
    "        df.loc[val, df.columns[col_number]] = REPLACE_WITH\n",
    "\n",
    "    return 1\n",
    "\n",
    "df1 = df.copy()\n",
    "for i,val in enumerate(i_change):\n",
    "    # print(i,val)\n",
    "    if(df.loc[val, df.columns[22]] == \"  Leica AT403 394315\"):\n",
    "        df_switch(i,val, df, coln_track_from, 22,\"  Leica AT403 394315\")\n",
    "    if(df.loc[val, df.columns[22]] == \"  Leica AT401 390741\"):\n",
    "        df_switch(i,val, df, coln_track_from, 22,\"  Leica AT401 390741\")\n",
    "    if(df.loc[val, df.columns[26]].split(\"eather\")[0] == \"  W\"):\n",
    "        df_switch(i,val, df, coln_track_from_rms, 26,\"  RMS 0 mm\")\n",
    "        # pass\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p = df.query(\"( value != value and not varx.isnull() ) or ( value.isnull() and not varx.isnull()  ) \"); print(p.to_markdown())\n",
    "len(p.index)\n",
    "# p=df.loc[i_change, df.columns[22:]].to_markdown();print(p)\n",
    "# len(df.columns)-len(coln_track_from_rms)-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMS Error                                                        RMS 0 mm\n",
       "Temperature                                               Weather:T=21.7C\n",
       "Pressure                                                P=1004.4hPA(mbar)\n",
       "Humidity                                                          H=61.7%\n",
       "Mode                       Measure Time Discrete Point Standard Pt. To SA\n",
       "Status                    emScon FAST Measurement Mode Used Laser Stat...\n",
       "Type measurement                                          Front/Back=True\n",
       "33                                                           Separate Obs\n",
       "Level compensation 1                         std components: 1 = 0.000000\n",
       "Level compensation 2                                         2 = 0.000000\n",
       "Level compensation 3                3 = 0.000000 mm Level Compensation ON\n",
       "varx                                                         3.096363e-04\n",
       "CoVar_xy                CoVar_xz    0.000009\\nCoVar_xz    0.000011\\nNa...\n",
       "CoVar_xy                CoVar_xz    0.000009\\nCoVar_xz    0.000011\\nNa...\n",
       "CoVar_xz                CoVar_yz   -0.000015\\nCoVar_yz    0.000303\\nNa...\n",
       "CoVar_xz                CoVar_yz   -0.000015\\nCoVar_yz    0.000303\\nNa...\n",
       "CoVar_xy                CoVar_xz    0.000009\\nCoVar_xz    0.000011\\nNa...\n",
       "CoVar_xy                CoVar_xz    0.000009\\nCoVar_xz    0.000011\\nNa...\n",
       "Var_y                   CoVar_xy   -0.000015\\nCoVar_xy    0.000316\\nNa...\n",
       "CoVar_yz                CoVar_xz    0.000009\\nCoVar_xz    0.000011\\nNa...\n",
       "CoVar_yz                CoVar_xz    0.000009\\nCoVar_xz    0.000011\\nNa...\n",
       "CoVar_xz                CoVar_yz   -0.000015\\nCoVar_yz    0.000303\\nNa...\n",
       "CoVar_xz                CoVar_yz   -0.000015\\nCoVar_yz    0.000303\\nNa...\n",
       "CoVar_yz                CoVar_xz    0.000009\\nCoVar_xz    0.000011\\nNa...\n",
       "CoVar_yz                CoVar_xz    0.000009\\nCoVar_xz    0.000011\\nNa...\n",
       "value                   CoVar_yz   -0.000015\\nCoVar_yz    0.000303\\nNa...\n",
       "Name: 2175, dtype: object"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = [2175,2178, 2192, 2211]\n",
    "if(df.loc[2175, df.columns[26]].split(\"eather\")[0] == \"  W\"):\n",
    "    print('Success')\n",
    "df.loc[2175, df.columns[26:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collection</th>\n",
       "      <th>Group</th>\n",
       "      <th>Point</th>\n",
       "      <th>R</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Phi</th>\n",
       "      <th>Planar offset</th>\n",
       "      <th>Radial offset</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>Level compensation 3</th>\n",
       "      <th>varx</th>\n",
       "      <th>CoVar_xy</th>\n",
       "      <th>CoVar_xz</th>\n",
       "      <th>CoVar_xy</th>\n",
       "      <th>Var_y</th>\n",
       "      <th>CoVar_yz</th>\n",
       "      <th>CoVar_xz</th>\n",
       "      <th>CoVar_yz</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Collection, Group, Point, R, Theta, Phi, Planar offset, Radial offset, 8, 9, 10, 11, 12, 13, 14, 15, [U-r], [U-theta], [U-phi], [U-mag], Timestamp, 21, Last Face, Tracker, Reflector, Target, RMS Error, Temperature, Pressure, Humidity, Mode, Status, Type measurement, 33, Level compensation 1, Level compensation 2, Level compensation 3, varx, CoVar_xy, CoVar_xz, CoVar_xy, Var_y, CoVar_yz, CoVar_xz, CoVar_yz, value]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 46 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"( value != value and not varx.isnull() ) or ( value.isnull() and not varx.isnull()  ) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "ver = 12\n",
    "file1 = f\"C:/Users/alelen/Documents/Export Data/All_points_{ver}.txt\"\n",
    "path = \"C:/Users/alelen/Documents/Export Data/\"\n",
    "fields = [\"Collection\"]\n",
    "# df = pd.read_csv(file1, skiprows=5, delimiter=\",\", on_bad_lines=\"skip\", usecols=fields, skip_blank_lines=True)\n",
    "# df = pd.read_csv(file1, skiprows=5, sep=\", \", on_bad_lines=\"skip\", skip_blank_lines=True)\n",
    "df = pd.read_csv(file1, skiprows=6, sep=\",\", header=None, on_bad_lines=\"skip\", skip_blank_lines=True, engine=\"python\")\n",
    "\n",
    "df.rename(columns={0:\"Collection\", 1:\"Group\", 2:\"Point\", 3:\"X\", 4:\"Y\", 5:\"Z\", 6:\"Planar offset\", 7:\"Radial offset\",\n",
    "                   16:\"[U-x]\", 17:\"[U-y]\", 18:\"[U-z]\", 19:\"[U-mag]\",\n",
    "                   20:\"Timestamp\", 22:\"Last Face\", 23:\"Tracker\", 24:\"Reflector\", 25:\"Target\",\n",
    "                   26:\"RMS Error\", 27:\"Temperature\", 28:\"Pressure\", 29:\"Humidity\",\n",
    "                   30:\"Mode\", 31:\"Status\", 32:\"Type measurement\", \n",
    "                   34:\"Level compensation 1\", 35:\"Level compensation 2\", 36:\"Level compensation 3\",\n",
    "                   37:\"[Var(x)]\", 38:\"[CoVar(xy)]\", 39:\"[CoVar(xz)]\", 40:\"[CoVar(xy)]\", 41:\"[Var(y)]\", 42:\"[CoVar(yz)]\", \n",
    "                   43:\"[CoVar(xz)]\", 44:\"[CoVar(yz)]\", 45:\"[Var(z)]\"},inplace=True)\n",
    "\n",
    "#df = pd.read_table(file1, skiprows=6, sep=\",  \", header=None, on_bad_lines=\"skip\", skip_blank_lines=True, engine=\"python\")\n",
    "\n",
    "#x = df.to_markdown(); print(x)\n",
    "# df.to_csv(path+f\"All_points_cleaned{ver}.txt\")\n",
    "\n",
    "df.tail(1)\n",
    "df['Temperature'] = df['Temperature'].str.removeprefix('  Weather:T=',)\n",
    "df['Pressure'] = df['Pressure'].str.lstrip('  P=',)\n",
    "df['Humidity'] = df['Humidity'].str.lstrip('  H=',)\n",
    "df['Humidity'] = df['Humidity'].str.rstrip('%',)\n",
    "# pd.to_numeric(df[\"Humidity\"])\n",
    "\n",
    "def celsius(fahrenheit): return round(5*(fahrenheit-32)/9,1)\n",
    "\n",
    "for i,val in enumerate(df['Temperature']):\n",
    "    if(val[-1]=='F'):\n",
    "        T = celsius(float(val.split('F')[0]))\n",
    "        df['Temperature'].iloc[i] = f'{T}C'\n",
    "\n",
    "def mPa(inHg): return round(inHg*33.863889532610884,1)\n",
    "\n",
    "for i,val in enumerate(df[\"Pressure\"]):\n",
    "    if(val[-1] == 'g'):\n",
    "        P = mPa(float(val.split('inHg')[0]))\n",
    "        df['Pressure'].iloc[i] = f'{P}hPA(mbar)'\n",
    "\n",
    "df[['Temperature', 'Pressure', 'Humidity']]\n",
    "df['Temperature'].str.rstrip('C')\n",
    "# x = df.to_markdown(); print(x)\n",
    "\n",
    "df['Temperature'] = df['Temperature'].str.rstrip('C')\n",
    "df['Pressure'] = df['Pressure'].str.rstrip('hPA(mbar)')\n",
    "df['Temperature'] = pd.to_numeric(df['Temperature'])\n",
    "df['Pressure'] = pd.to_numeric(df['Pressure'])\n",
    "df['Humidity'] = pd.to_numeric(df['Humidity'])\n",
    "\n",
    "df.to_csv(path+f\"All_points_cleaned{ver}.txt\")\n",
    "\n",
    "df[['[U-x]', '[U-y]', '[U-z]', '[U-mag]']].sort_values(by='[U-mag]')\n",
    "df[['Temperature', 'Pressure', 'Humidity']].sort_values(by='Temperature')\n",
    "\n",
    "\n",
    "df['Point'].str.strip().to_clipboard()\n",
    "df['Point'] = df['Point'].str.replace(\"  \", \"\")\n",
    "\n",
    "\n",
    "\n",
    "df['Group'] = df['Group'].str.replace(\"  \", \"\")\n",
    "df['Group'].unique()\n",
    "st = {}\n",
    "for i in df['Group'].unique():\n",
    "    st[i]=[0,0,0]\n",
    "st\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collection</th>\n",
       "      <th>Group</th>\n",
       "      <th>Point</th>\n",
       "      <th>R</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Phi</th>\n",
       "      <th>Planar offset</th>\n",
       "      <th>Radial offset</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>Level compensation 3</th>\n",
       "      <th>varx</th>\n",
       "      <th>CoVar_xy</th>\n",
       "      <th>CoVar_xz</th>\n",
       "      <th>CoVar_xy</th>\n",
       "      <th>Var_y</th>\n",
       "      <th>CoVar_yz</th>\n",
       "      <th>CoVar_xz</th>\n",
       "      <th>CoVar_yz</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5 Gev Ring tunnel survey</td>\n",
       "      <td>ST001</td>\n",
       "      <td>R115</td>\n",
       "      <td>153770.211476</td>\n",
       "      <td>1.786945</td>\n",
       "      <td>89.162990</td>\n",
       "      <td>19.05</td>\n",
       "      <td>19.05</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3 = 0.000002 in Level Compensation ON</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5 Gev Ring tunnel survey</td>\n",
       "      <td>ST001</td>\n",
       "      <td>R114</td>\n",
       "      <td>153846.809192</td>\n",
       "      <td>2.399460</td>\n",
       "      <td>89.164204</td>\n",
       "      <td>19.05</td>\n",
       "      <td>19.05</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3 = 0.000000 in Level Compensation ON</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5 Gev Ring tunnel survey</td>\n",
       "      <td>ST001</td>\n",
       "      <td>R110</td>\n",
       "      <td>149804.668692</td>\n",
       "      <td>1.831830</td>\n",
       "      <td>89.133978</td>\n",
       "      <td>19.05</td>\n",
       "      <td>19.05</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3 = 0.000022 in Level Compensation ON</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.002036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5 Gev Ring tunnel survey</td>\n",
       "      <td>ST001</td>\n",
       "      <td>R108</td>\n",
       "      <td>149850.862462</td>\n",
       "      <td>2.332035</td>\n",
       "      <td>89.136895</td>\n",
       "      <td>19.05</td>\n",
       "      <td>19.05</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3 = 0.000043 in Level Compensation ON</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5 Gev Ring tunnel survey</td>\n",
       "      <td>ST001</td>\n",
       "      <td>R001</td>\n",
       "      <td>157099.658668</td>\n",
       "      <td>2.350607</td>\n",
       "      <td>89.182969</td>\n",
       "      <td>19.05</td>\n",
       "      <td>19.05</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3 = 0.000006 in Level Compensation ON</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>Solution</td>\n",
       "      <td>FAS 200%</td>\n",
       "      <td>L0402</td>\n",
       "      <td>174074.122753</td>\n",
       "      <td>2.186592</td>\n",
       "      <td>83.192642</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>Solution</td>\n",
       "      <td>FAS 200%</td>\n",
       "      <td>L0401</td>\n",
       "      <td>174053.636506</td>\n",
       "      <td>1.993668</td>\n",
       "      <td>83.194695</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>Solution</td>\n",
       "      <td>FAS 200%</td>\n",
       "      <td>L0412</td>\n",
       "      <td>174514.572338</td>\n",
       "      <td>1.428822</td>\n",
       "      <td>81.896501</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>Solution</td>\n",
       "      <td>FAS 200%</td>\n",
       "      <td>Species F1</td>\n",
       "      <td>151552.087626</td>\n",
       "      <td>2.377873</td>\n",
       "      <td>80.113974</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>Solution</td>\n",
       "      <td>FAS 200%</td>\n",
       "      <td>Species F3</td>\n",
       "      <td>151619.677633</td>\n",
       "      <td>2.059874</td>\n",
       "      <td>80.095672</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2825 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Collection        Group         Point              R  \\\n",
       "0     1.5 Gev Ring tunnel survey        ST001          R115  153770.211476   \n",
       "1     1.5 Gev Ring tunnel survey        ST001          R114  153846.809192   \n",
       "2     1.5 Gev Ring tunnel survey        ST001          R110  149804.668692   \n",
       "3     1.5 Gev Ring tunnel survey        ST001          R108  149850.862462   \n",
       "4     1.5 Gev Ring tunnel survey        ST001          R001  157099.658668   \n",
       "...                          ...          ...           ...            ...   \n",
       "2820                    Solution    FAS 200%          L0402  174074.122753   \n",
       "2821                    Solution    FAS 200%          L0401  174053.636506   \n",
       "2822                    Solution    FAS 200%          L0412  174514.572338   \n",
       "2823                    Solution    FAS 200%     Species F1  151552.087626   \n",
       "2824                    Solution    FAS 200%     Species F3  151619.677633   \n",
       "\n",
       "         Theta        Phi  Planar offset  Radial offset   8   9  ...  \\\n",
       "0     1.786945  89.162990          19.05          19.05          ...   \n",
       "1     2.399460  89.164204          19.05          19.05          ...   \n",
       "2     1.831830  89.133978          19.05          19.05          ...   \n",
       "3     2.332035  89.136895          19.05          19.05          ...   \n",
       "4     2.350607  89.182969          19.05          19.05          ...   \n",
       "...        ...        ...            ...            ...  ..  ..  ...   \n",
       "2820  2.186592  83.192642           0.00           0.00          ...   \n",
       "2821  1.993668  83.194695           0.00           0.00          ...   \n",
       "2822  1.428822  81.896501           0.00           0.00          ...   \n",
       "2823  2.377873  80.113974           0.00           0.00          ...   \n",
       "2824  2.059874  80.095672           0.00           0.00          ...   \n",
       "\n",
       "                        Level compensation 3      varx  CoVar_xy  CoVar_xz  \\\n",
       "0      3 = 0.000002 in Level Compensation ON  0.000496 -0.000052  0.000069   \n",
       "1      3 = 0.000000 in Level Compensation ON  0.000472   0.00002  0.000067   \n",
       "2      3 = 0.000022 in Level Compensation ON  0.001014 -0.000136  0.000182   \n",
       "3      3 = 0.000043 in Level Compensation ON  0.000985  0.000014  0.000181   \n",
       "4      3 = 0.000006 in Level Compensation ON  0.000176 -0.000006 -0.000021   \n",
       "...                                      ...       ...       ...       ...   \n",
       "2820                                    None       NaN       NaN       NaN   \n",
       "2821                                    None       NaN       NaN       NaN   \n",
       "2822                                    None       NaN       NaN       NaN   \n",
       "2823                                    None       NaN       NaN       NaN   \n",
       "2824                                    None       NaN       NaN       NaN   \n",
       "\n",
       "      CoVar_xy     Var_y  CoVar_yz  CoVar_xz  CoVar_yz     value  \n",
       "0    -0.000052  0.000714  0.000016  0.000069  0.000016  0.000705  \n",
       "1      0.00002  0.000692 -0.000006  0.000067 -0.000006  0.000674  \n",
       "2    -0.000136   0.00205  0.000024  0.000182  0.000024  0.002036  \n",
       "3     0.000014  0.002035 -0.000002  0.000181 -0.000002  0.002004  \n",
       "4    -0.000006  0.000151  0.000005 -0.000021  0.000005  0.000167  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "2820       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2821       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2822       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2823       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2824       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[2825 rows x 46 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
